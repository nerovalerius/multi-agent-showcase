# LLM Showcase 

This repository is my portfolio of **Large Language Model (LLM) projects and experiments**.  
It demonstrates how I design, build, and deploy modern LLM-based AI systems:  
- from **prompt engineering** and **LangGraph agent flows**  
- to **retrieval-augmented generation (RAG)**  
- to **fine-tuning LLMs** (full, PEFT, LoRA/QLoRA)  
- to **containerized deployments** on **Azure ML** and edge devices.  

With a strong background in **AI engineering, data science, and scalable deployment**, I focus on **reproducible, production-ready pipelines** that bridge research and real-world applications.  

---

## 🔎 What’s Inside  

- **Prompt Engineering** – best practices & practical examples  
- **RAG Pipelines** – document Q&A with FAISS/Chroma  
- **LangGraph Flows** – modular conversational agents with tool integration  
- **LLM Fine-Tuning** – full training & parameter-efficient methods (LoRA, QLoRA, PEFT)  
- **MLOps & Deployment** – Dockerized workflows, Azure ML pipelines, DevOps integration  

---

## 🛠️ Tech Stack  

- **Languages & Libraries:** Python, PyTorch, pandas, LangChain, LangGraph, Hugging Face  
- **LLMs:** OpenAI (via API & Azure), Hugging Face models, fine-tuned models  
- **Apps & Interfaces:** Streamlit, FastAPI  
- **Deployment:** Docker, Azure ML, Azure DevOps  

---

## 📂 Structure  

```text
llm-showcase/
│── README.md
│── requirements.txt
│── notebooks/
│   ├── 01_prompting_basics.ipynb
│   ├── 02_rag_pipeline.ipynb
│   ├── 03_langgraph_agents.ipynb
│   └── 04_finetuning_llms.ipynb
│── apps/
│   ├── streamlit_chatbot/
│   └── langgraph_flow/
│── utils/
│   └── data_utils.py
